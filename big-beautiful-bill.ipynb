{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0be1ddc2bd2434",
   "metadata": {},
   "source": [
    "# GraphRAG Python package End-to-End Example\n",
    "\n",
    "This notebook contains an end-to-end worked example using the [GraphRAG Python package](https://neo4j.com/docs/neo4j-graphrag-python/current/index.html) for Neo4j. It starts with unstructured documents (in this case pdfs), and progresses through knowledge graph construction, knowledge graph retriever design, and complete GraphRAG pipelines. \n",
    "\n",
    "Research papers on Lupus are used as the data source. We design a couple of different retrievers based on different knowledge graph retrieval patterns. \n",
    "\n",
    "For more details and explanations around each of the below steps, see the [corresponding blog post](https://neo4j.com/blog/graphrag-python-package/) which contains a full write-up, in-depth comparison of the retrieval patterns, and additional learning resources."
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Setup the LLM endpoints on the GPU workstation:\n",
    "\n",
    "    # 1. vLLM (real 4-bit)\n",
    "    docker run -d --rm --gpus all -p 8001:8000 \\\n",
    "      -v $PWD/cache:/root/.cache/huggingface \\\n",
    "      vllm/vllm-openai:latest \\\n",
    "      --model Qwen/Qwen2-7B-Instruct-AWQ \\\n",
    "      --quantization awq \\\n",
    "      --served-model-name qwen2 \\\n",
    "      --dtype float16 \\\n",
    "      --port 8000\n",
    "\n",
    "    # 2. Infinity (smaller warm-up)\n",
    "    docker run -d --rm --gpus all -p 7997:7997 \\\n",
    "      -v $PWD/cache:/app/.cache \\\n",
    "      michaelf34/infinity:latest-trt-onnx \\\n",
    "      v2 --model-id BAAI/bge-large-en-v1.5 \\\n",
    "      --served-model-name bge \\\n",
    "      --batch-size 8 \\\n",
    "      --dtype float16 --device cuda --port 7997\n"
   ],
   "id": "a02f7521592f344f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Confirm that the endpoints work:\n",
    "\n",
    "    % http POST http://10.0.1.37:8001/v1/chat/completions \\\n",
    "         model=qwen2 \\\n",
    "         messages:='[\n",
    "           {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "           {\"role\": \"user\",   \"content\": \"Hello, world!\"}\n",
    "         ]' \\\n",
    "         temperature:=0.2 \\\n",
    "         max_tokens:=128\n",
    "\n",
    "    {\n",
    "        \"choices\": [\n",
    "            {\n",
    "                ...\n",
    "                \"message\": {\n",
    "                    \"content\": \"Hello! It's nice to meet you. How can I assist you today?\",\n",
    "                    ...\n",
    "                },\n",
    "                ...\n",
    "            }\n",
    "        ],\n",
    "        ...\n",
    "    }\n",
    "\n",
    "    % http POST http://10.0.1.37:7997/embeddings \\\n",
    "      model=bge \\\n",
    "      input:='[\"Natural-language string …\"]'\n",
    "\n",
    "    {\n",
    "        \"created\": 1749391848,\n",
    "        \"data\": [\n",
    "            {\n",
    "                \"embedding\": [\n",
    "                    0.02315451204776764,\n",
    "                    -0.02632719837129116,\n",
    "        -0.01859377510845661,\n",
    "                    0.018731053918600082,\n",
    "                    0.07425306737422943,\n",
    "                    -0.0092587536200881,\n",
    "                    ...\n",
    "                    0.00983075238764286,\n",
    "                    0.007191931363195181\n",
    "                ],\n",
    "                \"index\": 0,\n",
    "                \"object\": \"embedding\"\n",
    "            }\n",
    "        ],\n",
    "        \"id\": \"infinity-247581f8-4ae2-46f5-b62b-359eb461df7f\",\n",
    "        \"model\": \"bge\",\n",
    "        \"object\": \"list\",\n",
    "        \"usage\": {\n",
    "            \"prompt_tokens\": 25,\n",
    "            \"total_tokens\": 25\n",
    "        }\n",
    "    }\n",
    "\n"
   ],
   "id": "5648c7bad3f5d926"
  },
  {
   "cell_type": "code",
   "id": "9820f541adf30bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:15.665928Z",
     "start_time": "2025-06-10T19:45:14.851628Z"
    }
   },
   "source": [
    "%%capture\n",
  "%pip install fsspec langchain-text-splitters tiktoken openai python-dotenv numpy torch neo4j-graphrag==1.7.0"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "48847ca8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:15.791243Z",
     "start_time": "2025-06-10T19:45:15.789469Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"http://10.0.1.37:8001/v1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"dummy\"\n",
    "\n",
    "EMBEDDING_BASE  = \"http://10.0.1.37:7997\"\n",
    "EMBEDDING_MODEL = \"bge\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a023c71324bf6e7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:15.801746Z",
     "start_time": "2025-06-10T19:45:15.796873Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# load neo4j credentials (and openai api key in background).\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE')\n",
    "\n",
    "#uncomment this line if you aren't using a .env file\n",
    "# os.environ['OPENAI_API_KEY'] = 'copy_paste_the_openai_key_here'"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "418bd212bae7f492",
   "metadata": {},
   "source": [
    "## Knowledge Graph Building\n",
    "\n",
    "The `SimpleKGPipeline` class allows you to automatically build a knowledge graph with a few key inputs, including\n",
    "- a driver to connect to Neo4j,\n",
    "- an LLM for entity extraction, and\n",
    "- an embedding model to create vectors on text chunks for similarity search.\n",
    "\n",
    "There are also some optional inputs, such as node labels, relationship types, and a custom prompt template, which we will use to improve the quality of the knowledge graph. For full details on this, see [the blog](https://neo4j.com/blog/graphrag-python-package/).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3782c3fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:17.956939Z",
     "start_time": "2025-06-10T19:45:15.806759Z"
    }
   },
   "source": [
    "from openai import OpenAI\n",
    "from neo4j_graphrag.llm import OpenAILLM\n",
    "from neo4j_graphrag.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "LLM_BASE_URL = \"http://10.0.1.37:8001/v1\"   # vLLM server\n",
    "EMBEDDING_BASE_URL  = \"http://10.0.1.37:7997\"      # Infinity server\n",
    "EMBEDDING_MODEL = \"bge\"\n",
    "\n",
    "def make_clients():\n",
    "    # --- Embeddings ---------------------------------------------------------\n",
    "    embeddings = OpenAIEmbeddings(\n",
    "        EMBEDDING_MODEL,\n",
    "        base_url=EMBEDDING_BASE,   # http://10.0.1.37:7997\n",
    "        api_key=\"local\",           # dummy key; server ignores it\n",
    "        timeout=30.0, \n",
    "    )\n",
    "\n",
    "    # --- LLM ---------------------------------------------------------------\n",
    "    llm = OpenAILLM(\n",
    "        \"qwen2\",\n",
    "        base_url=os.environ[\"OPENAI_API_BASE\"],\n",
    "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "        timeout=60.0 \n",
    "    )\n",
    "    return llm, embeddings"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:18.049544Z",
     "start_time": "2025-06-10T19:45:17.963080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import neo4j\n",
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "driver        = neo4j.GraphDatabase.driver(NEO4J_URI,\n",
    "                                              auth=(NEO4J_USERNAME, NEO4J_PASSWORD),\n",
    "                                              database=NEO4J_DATABASE)\n",
    "llm, embedder = make_clients()\n",
    "splitter      = FixedSizeSplitter(400, 40)"
   ],
   "id": "aa30e35165325ec1",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:18.058190Z",
     "start_time": "2025-06-10T19:45:18.055407Z"
    }
   },
   "cell_type": "code",
   "source": [
    "NODE_TYPES = [\n",
    "    \"Bill\", \"Title\", \"Subtitle\", \"Section\", \"Agency\", \"Program\",\n",
    "    \"Requirement\", \"Appropriation\", \"BeneficiaryGroup\",\n",
    "    \"Deadline\", \"Act\"\n",
    "]\n",
    "\n",
    "RELATIONSHIP_TYPES = [\n",
    "    \"HAS_TITLE\", \"HAS_SUBTITLE\", \"HAS_SECTION\", \"ESTABLISHES\",\n",
    "    \"AUTHORIZES_FUNDS\", \"APPROPRIATES_TO\", \"IMPOSES_REQUIREMENT\",\n",
    "    \"BENEFITS\", \"AMENDS\", \"ADMINISTERED_BY\", \"AFFECTS\",\n",
    "    \"APPLIES_TO\", \"EFFECTIVE_ON\"\n",
    "]\n",
    "\n",
    "PATTERNS = [\n",
    "    (\"Bill\", \"HAS_TITLE\", \"Title\"),\n",
    "    (\"Title\", \"HAS_SUBTITLE\", \"Subtitle\"),\n",
    "    (\"Subtitle\", \"HAS_SECTION\", \"Section\"),\n",
    "    (\"Section\", \"HAS_SECTION\", \"Section\"),          # nested §§\n",
    "    (\"Section\", \"ESTABLISHES\", \"Program\"),\n",
    "    (\"Section\", \"AUTHORIZES_FUNDS\", \"Appropriation\"),\n",
    "    (\"Section\", \"IMPOSES_REQUIREMENT\", \"Requirement\"),\n",
    "    (\"Section\", \"BENEFITS\", \"BeneficiaryGroup\"),\n",
    "    (\"Section\", \"AMENDS\", \"Act\"),\n",
    "    (\"Program\", \"ADMINISTERED_BY\", \"Agency\"),\n",
    "    (\"Program\", \"BENEFITS\", \"BeneficiaryGroup\"),\n",
    "    (\"Appropriation\", \"APPROPRIATES_TO\", \"Program\"),\n",
    "    (\"Requirement\", \"AFFECTS\", \"Agency\"),\n",
    "    (\"Requirement\", \"APPLIES_TO\", \"BeneficiaryGroup\"),\n",
    "    (\"Section\", \"EFFECTIVE_ON\", \"Deadline\"),\n",
    "]"
   ],
   "id": "1f46a07eceb2bd99",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:18.065194Z",
     "start_time": "2025-06-10T19:45:18.063258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_schema_section() -> str:\n",
    "    \"\"\"Yield a markdown bulleted list that the LLM will see.\"\"\"\n",
    "    nodes = \"\\n\".join(f\"* **{n}**\" for n in NODE_TYPES)\n",
    "    rels  = \"\\n\".join(f\"* `{r}`\"  for r in RELATIONSHIP_TYPES)\n",
    "    return f\"\"\"\n",
    "**Node labels**\n",
    "\n",
    "{nodes}\n",
    "\n",
    "**Relationship types**\n",
    "\n",
    "{rels}\n",
    "\"\"\".strip()"
   ],
   "id": "ac291dfe269395fc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "8cbcdedcd1757b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:18.072374Z",
     "start_time": "2025-06-10T19:45:18.070608Z"
    }
   },
   "source": [
  "prompt_template = \"\"\"\n",
  "You are a legislative analyst tasked with extracting structured information from U.S. federal bills and representing it as a property graph that will power a GraphRAG question-answering system.\n",
    "\n",
    "**Task**\n",
    "\n",
    "1. **Extract every entity** (node) the *Input text* clearly mentions and assign\n",
    "   it one of the allowed labels below.\n",
    "2. **Extract every relationship** that exists *within* the *Input text*, using\n",
    "   the correct direction (from the `start_node_id` to the `end_node_id`).\n",
    "\n",
    "**Output format**\n",
    "\n",
  "Return **only** a single JSON object in the form\n",
  "\n",
  "{{{{\n",
  "  \"nodes\": [\n",
  "    {{{{ \"id\": \"0\", \"label\": \"<NodeLabel>\", \"properties\": {{{{ \"name\": \"<entity name>\" }}}} }}}},\n",
  "    ...\n",
  "  ],\n",
  "  \"relationships\": [\n",
  "    {{{{ \"type\": \"<REL_TYPE>\", \"start_node_id\": \"0\", \"end_node_id\": \"1\", \"properties\": {{{{ \"details\": \"<optional short description>\" }}}} }}}},\n",
  "    ...\n",
  "  ]\n",
  "}}}}\n",
    "\n",
    "* Each `id` must be unique *within this chunk*.\n",
    "* Include only properties that appear literally in the text.\n",
    "* If the input is empty return `{{}}`.\n",
    "\n",
    "**Allowed node labels and relationship types**\n",
    "\n",
    "{schema}\n",
    "\n",
    "**Guidelines**\n",
    "\n",
    "* Do **not** invent information not present in the text.\n",
    "* Use the containment edges (`HAS_TITLE`, `HAS_SUBTITLE`, `HAS_SECTION`).\n",
    "* Use policy-specific edges (`APPROPRIATES_TO`, `EFFECTIVE_ON`, …) only when\n",
    "  the text supports them.\n",
    "* Keep entity types general so they can be reused across bills.\n",
    "\n",
    "**Few-shot examples**\n",
    "\n",
    "{examples}\n",
    "\n",
    "---\n",
    "\n",
    "**Input text**\n",
    "\n",
    "{text}\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:18.079260Z",
     "start_time": "2025-06-10T19:45:18.077823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt_ready = prompt_template.format(\n",
    "    schema=build_schema_section(),\n",
    "    examples=\"\",\n",
    "    text=\"{text}\"\n",
    ")"
   ],
   "id": "e379933631018cfb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:18.087836Z",
     "start_time": "2025-06-10T19:45:18.085206Z"
    }
   },
   "cell_type": "code",
   "source": "print(prompt_ready)",
   "id": "c88f868c1a2f184a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a legislative analyst tasked with extracting structured information from U.S. federal bills and representing it as a property graph that will power a GraphRAG question-answering system.\n",
      "\n",
      "**Task**\n",
      "\n",
      "1. **Extract every entity** (node) the *Input text* clearly mentions and assign\n",
      "   it one of the allowed labels below.\n",
      "2. **Extract every relationship** that exists *within* the *Input text*, using\n",
      "   the correct direction (from the `start_node_id` to the `end_node_id`).\n",
      "\n",
      "**Output format**\n",
      "\n",
      "Return **only** a single JSON object in the form\n",
      "\n",
      "{{\n",
      "  \"nodes\": [\n",
      "    {{ \"id\": \"0\",\n",
      "       \"label\": \"<NodeLabel>\",\n",
      "       \"properties\": {{ \"name\": \"<entity name>\" }} }},\n",
      "    …\n",
      "  ],\n",
      "  \"relationships\": [\n",
      "    {{ \"type\": \"<REL_TYPE>\",\n",
      "       \"start_node_id\": \"0\",\n",
      "       \"end_node_id\": \"1\",\n",
      "       \"properties\": {{ \"details\": \"<optional short description>\" }} }},\n",
      "    …\n",
      "  ]\n",
      "}}\n",
      "\n",
      "* Each `id` must be unique *within this chunk*.\n",
      "* Include only properties that appear literally in the text.\n",
      "* If the input is empty return `{}`.\n",
      "\n",
      "**Allowed node labels and relationship types**\n",
      "\n",
      "**Node labels**\n",
      "\n",
      "* **Bill**\n",
      "* **Title**\n",
      "* **Subtitle**\n",
      "* **Section**\n",
      "* **Agency**\n",
      "* **Program**\n",
      "* **Requirement**\n",
      "* **Appropriation**\n",
      "* **BeneficiaryGroup**\n",
      "* **Deadline**\n",
      "* **Act**\n",
      "\n",
      "**Relationship types**\n",
      "\n",
      "* `HAS_TITLE`\n",
      "* `HAS_SUBTITLE`\n",
      "* `HAS_SECTION`\n",
      "* `ESTABLISHES`\n",
      "* `AUTHORIZES_FUNDS`\n",
      "* `APPROPRIATES_TO`\n",
      "* `IMPOSES_REQUIREMENT`\n",
      "* `BENEFITS`\n",
      "* `AMENDS`\n",
      "* `ADMINISTERED_BY`\n",
      "* `AFFECTS`\n",
      "* `APPLIES_TO`\n",
      "* `EFFECTIVE_ON`\n",
      "\n",
      "**Guidelines**\n",
      "\n",
      "* Do **not** invent information not present in the text.\n",
      "* Use the containment edges (`HAS_TITLE`, `HAS_SUBTITLE`, `HAS_SECTION`).\n",
      "* Use policy-specific edges (`APPROPRIATES_TO`, `EFFECTIVE_ON`, …) only when\n",
      "  the text supports them.\n",
      "* Keep entity types general so they can be reused across bills.\n",
      "\n",
      "**Few-shot examples**\n",
      "\n",
      "\n",
      "\n",
      "---\n",
      "\n",
      "**Input text**\n",
      "\n",
      "{text}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "1c4fb1fbd97f7503",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:19.708538Z",
     "start_time": "2025-06-10T19:45:18.097795Z"
    }
   },
   "source": [
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "\n",
    "kg_builder = SimpleKGPipeline(\n",
    "    llm=llm,\n",
    "    driver=driver,\n",
    "    text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
    "    embedder=embedder,\n",
    "    entities=NODE_TYPES,\n",
    "    relations=RELATIONSHIP_TYPES,\n",
    "    enforce_schema=\"STRICT\",\n",
    "    prompt_template = prompt_template.format(\n",
    "        schema   = build_schema_section(),\n",
    "        examples = None,\n",
    "        text     = \"{text}\"\n",
    "    ),\n",
    "    from_pdf=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "672cdd9cd894d530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-10T19:45:20.922112Z",
     "start_time": "2025-06-10T19:45:19.717564Z"
    }
   },
   "source": [
    "pdf_file_paths = ['BILLS-119hr1rh-sample.pdf']\n",
    "\n",
    "for path in pdf_file_paths:\n",
    "    print(f\"Processing : {path}\")\n",
    "    pdf_result = await kg_builder.run_async(file_path=path)\n",
    "    print(f\"Result: {pdf_result}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing : BILLS-119hr1rh-sample.pdf\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Replacement index 0 out of range for positional args tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m pdf_file_paths:\n\u001B[32m      4\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mProcessing : \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     pdf_result = \u001B[38;5;28;01mawait\u001B[39;00m kg_builder.run_async(file_path=path)\n\u001B[32m      6\u001B[39m     \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mResult: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpdf_result\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/kg_builder.py:137\u001B[39m, in \u001B[36mSimpleKGPipeline.run_async\u001B[39m\u001B[34m(self, file_path, text)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mrun_async\u001B[39m(\n\u001B[32m    125\u001B[39m     \u001B[38;5;28mself\u001B[39m, file_path: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m, text: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    126\u001B[39m ) -> PipelineResult:\n\u001B[32m    127\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    128\u001B[39m \u001B[33;03m    Asynchronously runs the knowledge graph building process.\u001B[39;00m\n\u001B[32m    129\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    135\u001B[39m \u001B[33;03m        PipelineResult: The result of the pipeline execution.\u001B[39;00m\n\u001B[32m    136\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m137\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.runner.run({\u001B[33m\"\u001B[39m\u001B[33mfile_path\u001B[39m\u001B[33m\"\u001B[39m: file_path, \u001B[33m\"\u001B[39m\u001B[33mtext\u001B[39m\u001B[33m\"\u001B[39m: text})\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/config/runner.py:130\u001B[39m, in \u001B[36mPipelineRunner.run\u001B[39m\u001B[34m(self, user_input)\u001B[39m\n\u001B[32m    126\u001B[39m     run_param = deep_update(\u001B[38;5;28mself\u001B[39m.run_params, user_input)\n\u001B[32m    127\u001B[39m logger.info(\n\u001B[32m    128\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPIPELINE_RUNNER: starting pipeline \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.pipeline\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m with run_params=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprettify(run_param)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    129\u001B[39m )\n\u001B[32m--> \u001B[39m\u001B[32m130\u001B[39m result = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pipeline.run(data=run_param)\n\u001B[32m    131\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.do_cleaning:\n\u001B[32m    132\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:573\u001B[39m, in \u001B[36mPipeline.run\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    571\u001B[39m orchestrator = Orchestrator(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    572\u001B[39m logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPIPELINE ORCHESTRATOR: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morchestrator.run_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m573\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m orchestrator.run(data)\n\u001B[32m    574\u001B[39m end_time = default_timer()\n\u001B[32m    575\u001B[39m logger.debug(\n\u001B[32m    576\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mPIPELINE FINISHED \u001B[39m\u001B[38;5;132;01m{\u001B[39;00morchestrator.run_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mend_time\u001B[38;5;250m \u001B[39m-\u001B[38;5;250m \u001B[39mstart_time\u001B[38;5;132;01m}\u001B[39;00m\u001B[33ms\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    577\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:270\u001B[39m, in \u001B[36mOrchestrator.run\u001B[39m\u001B[34m(self, data)\u001B[39m\n\u001B[32m    268\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.event_notifier.notify_pipeline_started(\u001B[38;5;28mself\u001B[39m.run_id, data)\n\u001B[32m    269\u001B[39m tasks = [\u001B[38;5;28mself\u001B[39m.run_task(root, data) \u001B[38;5;28;01mfor\u001B[39;00m root \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pipeline.roots()]\n\u001B[32m--> \u001B[39m\u001B[32m270\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*tasks)\n\u001B[32m    271\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.event_notifier.notify_pipeline_finished(\n\u001B[32m    272\u001B[39m     \u001B[38;5;28mself\u001B[39m.run_id, \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.pipeline.get_final_results(\u001B[38;5;28mself\u001B[39m.run_id)\n\u001B[32m    273\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:93\u001B[39m, in \u001B[36mOrchestrator.run_task\u001B[39m\u001B[34m(self, task, data)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.event_notifier.notify_task_finished(\u001B[38;5;28mself\u001B[39m.run_id, task.name, res)\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m res:\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_task_complete(data=data, task=task, result=res)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:134\u001B[39m, in \u001B[36mOrchestrator.on_task_complete\u001B[39m\u001B[34m(self, data, task, result)\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.add_result_for_component(\n\u001B[32m    130\u001B[39m     task.name, res_to_save, is_final=task.is_leaf()\n\u001B[32m    131\u001B[39m )\n\u001B[32m    132\u001B[39m \u001B[38;5;66;03m# then get the next tasks to be executed\u001B[39;00m\n\u001B[32m    133\u001B[39m \u001B[38;5;66;03m# and run them in //\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*[\u001B[38;5;28mself\u001B[39m.run_task(n, data) \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.next(task)])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:93\u001B[39m, in \u001B[36mOrchestrator.run_task\u001B[39m\u001B[34m(self, task, data)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.event_notifier.notify_task_finished(\u001B[38;5;28mself\u001B[39m.run_id, task.name, res)\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m res:\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_task_complete(data=data, task=task, result=res)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:134\u001B[39m, in \u001B[36mOrchestrator.on_task_complete\u001B[39m\u001B[34m(self, data, task, result)\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.add_result_for_component(\n\u001B[32m    130\u001B[39m     task.name, res_to_save, is_final=task.is_leaf()\n\u001B[32m    131\u001B[39m )\n\u001B[32m    132\u001B[39m \u001B[38;5;66;03m# then get the next tasks to be executed\u001B[39;00m\n\u001B[32m    133\u001B[39m \u001B[38;5;66;03m# and run them in //\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*[\u001B[38;5;28mself\u001B[39m.run_task(n, data) \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.next(task)])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:93\u001B[39m, in \u001B[36mOrchestrator.run_task\u001B[39m\u001B[34m(self, task, data)\u001B[39m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.event_notifier.notify_task_finished(\u001B[38;5;28mself\u001B[39m.run_id, task.name, res)\n\u001B[32m     92\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m res:\n\u001B[32m---> \u001B[39m\u001B[32m93\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.on_task_complete(data=data, task=task, result=res)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:134\u001B[39m, in \u001B[36mOrchestrator.on_task_complete\u001B[39m\u001B[34m(self, data, task, result)\u001B[39m\n\u001B[32m    129\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.add_result_for_component(\n\u001B[32m    130\u001B[39m     task.name, res_to_save, is_final=task.is_leaf()\n\u001B[32m    131\u001B[39m )\n\u001B[32m    132\u001B[39m \u001B[38;5;66;03m# then get the next tasks to be executed\u001B[39;00m\n\u001B[32m    133\u001B[39m \u001B[38;5;66;03m# and run them in //\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m134\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*[\u001B[38;5;28mself\u001B[39m.run_task(n, data) \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.next(task)])\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/orchestrator.py:89\u001B[39m, in \u001B[36mOrchestrator.run_task\u001B[39m\u001B[34m(self, task, data)\u001B[39m\n\u001B[32m     83\u001B[39m notifier = partial(\n\u001B[32m     84\u001B[39m     \u001B[38;5;28mself\u001B[39m.event_notifier.notify_task_progress,\n\u001B[32m     85\u001B[39m     run_id=\u001B[38;5;28mself\u001B[39m.run_id,\n\u001B[32m     86\u001B[39m     task_name=task.name,\n\u001B[32m     87\u001B[39m )\n\u001B[32m     88\u001B[39m context = RunContext(run_id=\u001B[38;5;28mself\u001B[39m.run_id, task_name=task.name, notifier=notifier)\n\u001B[32m---> \u001B[39m\u001B[32m89\u001B[39m res = \u001B[38;5;28;01mawait\u001B[39;00m task.run(context, inputs)\n\u001B[32m     90\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.set_task_status(task.name, RunStatus.DONE)\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.event_notifier.notify_task_finished(\u001B[38;5;28mself\u001B[39m.run_id, task.name, res)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:104\u001B[39m, in \u001B[36mTaskPipelineNode.run\u001B[39m\u001B[34m(self, context, inputs)\u001B[39m\n\u001B[32m    102\u001B[39m logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTASK START \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.name\u001B[38;5;132;01m=}\u001B[39;00m\u001B[33m input=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprettify(inputs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    103\u001B[39m start_time = default_timer()\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m res = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.execute(context, inputs)\n\u001B[32m    105\u001B[39m end_time = default_timer()\n\u001B[32m    106\u001B[39m logger.debug(\n\u001B[32m    107\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTASK FINISHED \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.name\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m in \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mend_time\u001B[38;5;250m \u001B[39m-\u001B[38;5;250m \u001B[39mstart_time\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m res=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprettify(res)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m    108\u001B[39m )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/pipeline.py:90\u001B[39m, in \u001B[36mTaskPipelineNode.execute\u001B[39m\u001B[34m(self, context, inputs)\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mexecute\u001B[39m(\n\u001B[32m     81\u001B[39m     \u001B[38;5;28mself\u001B[39m, context: RunContext, inputs: \u001B[38;5;28mdict\u001B[39m[\u001B[38;5;28mstr\u001B[39m, Any]\n\u001B[32m     82\u001B[39m ) -> RunResult | \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m     83\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Execute the task\u001B[39;00m\n\u001B[32m     84\u001B[39m \n\u001B[32m     85\u001B[39m \u001B[33;03m    Returns:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     88\u001B[39m \u001B[33;03m        was unsuccessful.\u001B[39;00m\n\u001B[32m     89\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m90\u001B[39m     component_result = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.component.run_with_context(\n\u001B[32m     91\u001B[39m         context_=context, **inputs\n\u001B[32m     92\u001B[39m     )\n\u001B[32m     93\u001B[39m     run_result = RunResult(\n\u001B[32m     94\u001B[39m         result=component_result,\n\u001B[32m     95\u001B[39m     )\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m run_result\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/pipeline/component.py:110\u001B[39m, in \u001B[36mComponent.run_with_context\u001B[39m\u001B[34m(self, context_, *args, **kwargs)\u001B[39m\n\u001B[32m     98\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"This method is called by the pipeline orchestrator.\u001B[39;00m\n\u001B[32m     99\u001B[39m \u001B[33;03mThe `context_` parameter contains information about\u001B[39;00m\n\u001B[32m    100\u001B[39m \u001B[33;03mthe pipeline run: the `run_id` and a `notify` function\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    107\u001B[39m \u001B[33;03mIt defaults to calling the `run` method to prevent any breaking change.\u001B[39;00m\n\u001B[32m    108\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    109\u001B[39m \u001B[38;5;66;03m# default behavior to prevent a breaking change\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m110\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.run(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:34\u001B[39m, in \u001B[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m     32\u001B[39m \u001B[38;5;129m@functools\u001B[39m.wraps(wrapped)\n\u001B[32m     33\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrapper_function\u001B[39m(*args, **kwargs):  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m34\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m wrapper(*args, **kwargs)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/entity_relation_extractor.py:341\u001B[39m, in \u001B[36mLLMEntityRelationExtractor.run\u001B[39m\u001B[34m(self, chunks, document_info, lexical_graph_config, schema, examples, **kwargs)\u001B[39m\n\u001B[32m    330\u001B[39m sem = asyncio.Semaphore(\u001B[38;5;28mself\u001B[39m.max_concurrency)\n\u001B[32m    331\u001B[39m tasks = [\n\u001B[32m    332\u001B[39m     \u001B[38;5;28mself\u001B[39m.run_for_chunk(\n\u001B[32m    333\u001B[39m         sem,\n\u001B[32m   (...)\u001B[39m\u001B[32m    339\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m chunk \u001B[38;5;129;01min\u001B[39;00m chunks.chunks\n\u001B[32m    340\u001B[39m ]\n\u001B[32m--> \u001B[39m\u001B[32m341\u001B[39m chunk_graphs: \u001B[38;5;28mlist\u001B[39m[Neo4jGraph] = \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28;01mawait\u001B[39;00m asyncio.gather(*tasks))\n\u001B[32m    342\u001B[39m graph = \u001B[38;5;28mself\u001B[39m.combine_chunk_graphs(lexical_graph, chunk_graphs)\n\u001B[32m    343\u001B[39m logger.debug(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mExtracted graph: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprettify(graph)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/entity_relation_extractor.py:284\u001B[39m, in \u001B[36mLLMEntityRelationExtractor.run_for_chunk\u001B[39m\u001B[34m(self, sem, chunk, schema, examples, lexical_graph_builder)\u001B[39m\n\u001B[32m    282\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Run extraction, validation and post processing for a single chunk\"\"\"\u001B[39;00m\n\u001B[32m    283\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mwith\u001B[39;00m sem:\n\u001B[32m--> \u001B[39m\u001B[32m284\u001B[39m     chunk_graph = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.extract_for_chunk(schema, examples, chunk)\n\u001B[32m    285\u001B[39m     final_chunk_graph = \u001B[38;5;28mself\u001B[39m.validate_chunk(chunk_graph, schema)\n\u001B[32m    286\u001B[39m     \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.post_process_chunk(\n\u001B[32m    287\u001B[39m         final_chunk_graph,\n\u001B[32m    288\u001B[39m         chunk,\n\u001B[32m    289\u001B[39m         lexical_graph_builder,\n\u001B[32m    290\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/experimental/components/entity_relation_extractor.py:215\u001B[39m, in \u001B[36mLLMEntityRelationExtractor.extract_for_chunk\u001B[39m\u001B[34m(self, schema, examples, chunk)\u001B[39m\n\u001B[32m    211\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mextract_for_chunk\u001B[39m(\n\u001B[32m    212\u001B[39m     \u001B[38;5;28mself\u001B[39m, schema: SchemaConfig, examples: \u001B[38;5;28mstr\u001B[39m, chunk: TextChunk\n\u001B[32m    213\u001B[39m ) -> Neo4jGraph:\n\u001B[32m    214\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Run entity extraction for a given text chunk.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m215\u001B[39m     prompt = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprompt_template\u001B[49m\u001B[43m.\u001B[49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    216\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m=\u001B[49m\u001B[43mchunk\u001B[49m\u001B[43m.\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m=\u001B[49m\u001B[43mschema\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmodel_dump\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m=\u001B[49m\u001B[43mexamples\u001B[49m\n\u001B[32m    217\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    218\u001B[39m     llm_result = \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.llm.ainvoke(prompt)\n\u001B[32m    219\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/generation/prompts.py:92\u001B[39m, in \u001B[36mPromptTemplate.format\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m     90\u001B[39m data = kwargs\n\u001B[32m     91\u001B[39m data.update({k: v \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m.expected_inputs, args)})\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_format\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/anaconda3/envs/neo4j/lib/python3.11/site-packages/neo4j_graphrag/generation/prompts.py:61\u001B[39m, in \u001B[36mPromptTemplate._format\u001B[39m\u001B[34m(self, **kwargs)\u001B[39m\n\u001B[32m     59\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m e \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs:\n\u001B[32m     60\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m PromptMissingInputError(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mMissing input \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m61\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtemplate\u001B[49m\u001B[43m.\u001B[49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mIndexError\u001B[39m: Replacement index 0 out of range for positional args tuple"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "\n",
    "create_vector_index(driver, name=\"text_embeddings\", label=\"Chunk\",\n",
    "                    embedding_property=\"embedding\", dimensions=1024, similarity_fn=\"cosine\")"
   ],
   "id": "dab8d7a27e0ae272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# STOP",
   "id": "a49caea436c57181"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Knowledge Graph Retrieval",
   "id": "efae0f207dbab678"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "vector_retriever = VectorRetriever(\n",
    "    driver,\n",
    "    index_name=\"text_embeddings\",\n",
    "    embedder=embedder,\n",
    "    return_properties=[\"text\"],\n",
    ")"
   ],
   "id": "b94dec882cb754ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ac578277",
   "metadata": {},
   "source": [
    "# … rest of your notebook stays unchanged …\n",
    "chunks  = splitter(text)\n",
    "vectors = embedder.embed([c.text for c in chunks])\n",
    "result  = await llm.ainvoke(prompt_template.format(text=text))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "48e4bff5",
   "metadata": {},
   "source": [
    "prompt = prompt_template.format(text=some_text, schema=my_schema_json)\n",
    "result = await llm.ainvoke(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "529a3392",
   "metadata": {},
   "source": [
    "llm, embedder = make_clients()\n",
    "\n",
    "chunks  = splitter.split(text)\n",
    "vectors = embedder.embed([c.text for c in chunks])\n",
    "result  = await llm.ainvoke(prompt)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94e1dfac980e6527",
   "metadata": {},
   "source": [
    "from neo4j_graphrag.experimental.components.text_splitters.fixed_size_splitter import FixedSizeSplitter\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "\n",
    "kg_builder_pdf = SimpleKGPipeline(\n",
    "    llm=ex_llm,\n",
    "    driver=driver,\n",
    "    text_splitter=FixedSizeSplitter(chunk_size=500, chunk_overlap=100),\n",
    "    embedder=embedder,\n",
    "    entities=node_labels,\n",
    "    relations=rel_types,\n",
    "    prompt_template=prompt_template,\n",
    "    from_pdf=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4d8ef81d0b5ac70c",
   "metadata": {},
   "source": [
    "Below, we run the `SimpleKGPipeline` to construct our knowledge graph from 3 pdf documents and store in Neo4j."
   ]
  },
  {
   "cell_type": "code",
   "id": "edeee98826a970a8",
   "metadata": {},
   "source": [
    "pdf_file_paths = ['BILLS-119hr1rh.pdf']\n",
    "\n",
    "for path in pdf_file_paths:\n",
    "    print(f\"Processing : {path}\")\n",
    "    pdf_result = await kg_builder_pdf.run_async(file_path=path)\n",
    "    print(f\"Result: {pdf_result}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a9c0fd965b15b143",
   "metadata": {},
   "source": [
    "## Knowledge Graph Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7b98e310104246",
   "metadata": {},
   "source": [
    "We will leverage Neo4j's vector search capabilities here. To do this, we need to begin by creating a vector index on the text chunks from the PDFs, which are stored on `Chunk` nodes in our knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "id": "940b051107b89204",
   "metadata": {},
   "source": [
    "from neo4j_graphrag.indexes import create_vector_index\n",
    "\n",
    "create_vector_index(driver, name=\"text_embeddings\", label=\"Chunk\",\n",
    "                    embedding_property=\"embedding\", dimensions=1536, similarity_fn=\"cosine\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ec95391c989ee694",
   "metadata": {},
   "source": [
    "Now that the index is set up, we will start simple with a __VectorRetriever__.  The __VectorRetriever__ just queries `Chunk` nodes via vector search, bringing back the text and some metadata."
   ]
  },
  {
   "cell_type": "code",
   "id": "eeda7e519c60a02b",
   "metadata": {},
   "source": [
    "from neo4j_graphrag.retrievers import VectorRetriever\n",
    "\n",
    "vector_retriever = VectorRetriever(\n",
    "    driver,\n",
    "    index_name=\"text_embeddings\",\n",
    "    embedder=embedder,\n",
    "    return_properties=[\"text\"],\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "982112cc273a472e",
   "metadata": {},
   "source": [
    "Below we visualize the context we get back when submitting a search prompt. "
   ]
  },
  {
   "cell_type": "code",
   "id": "ca27731a1f99d71d",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "vector_res = vector_retriever.get_search_results(query_text = \"How is precision medicine applied to Lupus?\", \n",
    "                                                 top_k=3)\n",
    "for i in vector_res.records: print(\"====\\n\" + json.dumps(i.data(), indent=4))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2b2ee3da2339365f",
   "metadata": {},
   "source": [
    "The GraphRAG Python Package offers [a wide range of useful retrievers](https://neo4j.com/docs/neo4j-graphrag-python/current/user_guide_rag.html#retriever-configuration), each covering different knowledge graph retrieval patterns.\n",
    "\n",
    "Below we will use the __`VectorCypherRetriever`__, which allows you to run a graph traversal after finding nodes with vector search.  This uses Cypher, Neo4j's graph query language, to define the logic for traversing the graph. \n",
    "\n",
    "As a simple starting point, we'll traverse up to 3 hops out from each Chunk, capture the relationships encountered, and include them in the response alongside our text chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2c81ad815a7b1bf9",
   "metadata": {},
   "source": [
    "from neo4j_graphrag.retrievers import VectorCypherRetriever\n",
    "\n",
    "vc_retriever = VectorCypherRetriever(\n",
    "    driver,\n",
    "    index_name=\"text_embeddings\",\n",
    "    embedder=embedder,\n",
    "    retrieval_query=\"\"\"\n",
    "//1) Go out 2-3 hops in the entity graph and get relationships\n",
    "WITH node AS chunk\n",
    "MATCH (chunk)<-[:FROM_CHUNK]-()-[relList:!FROM_CHUNK]-{1,2}()\n",
    "UNWIND relList AS rel\n",
    "\n",
    "//2) collect relationships and text chunks\n",
    "WITH collect(DISTINCT chunk) AS chunks, \n",
    "  collect(DISTINCT rel) AS rels\n",
    "\n",
    "//3) format and return context\n",
    "RETURN '=== text ===\\n' + apoc.text.join([c in chunks | c.text], '\\n---\\n') + '\\n\\n=== kg_rels ===\\n' +\n",
    "  apoc.text.join([r in rels | startNode(r).name + ' - ' + type(r) + '(' + coalesce(r.details, '') + ')' +  ' -> ' + endNode(r).name ], '\\n---\\n') AS info\n",
    "\"\"\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ef5183123679ca2d",
   "metadata": {},
   "source": [
    "Below we visualize the context we get back when submitting a search prompt. "
   ]
  },
  {
   "cell_type": "code",
   "id": "4a1df583f2450f35",
   "metadata": {},
   "source": [
    "vc_res = vc_retriever.get_search_results(query_text = \"How is precision medicine applied to Lupus?\", top_k=3)\n",
    "\n",
    "# print output\n",
    "kg_rel_pos = vc_res.records[0]['info'].find('\\n\\n=== kg_rels ===\\n')\n",
    "print(\"# Text Chunk Context:\")\n",
    "print(vc_res.records[0]['info'][:kg_rel_pos])\n",
    "print(\"# KG Context From Relationships:\")\n",
    "print(vc_res.records[0]['info'][kg_rel_pos:])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f2e55b8b3511cf1",
   "metadata": {},
   "source": [
    "## GraphRAG\n",
    " \n",
    " You can construct GraphRAG pipelines with the `GraphRAG` class.  At a minimum, you will need to pass the constructor an LLM and a retriever. You can optionally pass a custom prompt template. We will do so here just to provide a bit more guidance for the LLM to stick to information from our data source.\n",
    " \n",
    "Below we create `GraphRAG` objects for both the vector and vector-cypher retrievers. "
   ]
  },
  {
   "cell_type": "code",
   "id": "8e2cf317a83d59ae",
   "metadata": {},
   "source": [
    "from neo4j_graphrag.llm import OpenAILLM as LLM\n",
    "from neo4j_graphrag.generation import RagTemplate\n",
    "from neo4j_graphrag.generation.graphrag import GraphRAG\n",
    "\n",
    "llm = LLM(model_name=\"qwen2\",  model_params={\"temperature\": 0.0})\n",
    "\n",
    "rag_template = RagTemplate(template='''Answer the Question using the following Context. Only respond with information mentioned in the Context. Do not inject any speculative information not mentioned. \n",
    "\n",
    "# Question:\n",
    "{query_text}\n",
    " \n",
    "# Context:\n",
    "{context}\n",
    "\n",
    "# Answer:\n",
    "''', expected_inputs=['query_text', 'context'])\n",
    "\n",
    "v_rag  = GraphRAG(llm=llm, retriever=vector_retriever, prompt_template=rag_template)\n",
    "vc_rag = GraphRAG(llm=llm, retriever=vc_retriever, prompt_template=rag_template)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "fc8e13302fdeadd3",
   "metadata": {},
   "source": [
    "Now we can run GraphRAG and examine the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "id": "4d0aff643e689611",
   "metadata": {},
   "source": [
    "q = \"How is precision medicine applied to Lupus? provide in list format.\"\n",
    "print(f\"Vector Response: \\n{v_rag.search(q, retriever_config={'top_k':5}).answer}\")\n",
    "print(\"\\n===========================\\n\")\n",
    "print(f\"Vector + Cypher Response: \\n{vc_rag.search(q, retriever_config={'top_k':5}).answer}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2c44f834bdb13ad",
   "metadata": {},
   "source": [
    "q = \"Can you summarize systemic lupus erythematosus (SLE)? including common effects, biomarkers, and treatments? Provide in detailed list format.\"\n",
    "\n",
    "v_rag_result = v_rag.search(q, retriever_config={'top_k': 5}, return_context=True)\n",
    "vc_rag_result = vc_rag.search(q, retriever_config={'top_k': 5}, return_context=True)\n",
    "\n",
    "print(f\"Vector Response: \\n{v_rag_result.answer}\")\n",
    "print(\"\\n===========================\\n\")\n",
    "print(f\"Vector + Cypher Response: \\n{vc_rag_result.answer}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1088766f7109b6b3",
   "metadata": {},
   "source": [
    "for i in v_rag_result.retriever_result.items: print(json.dumps(eval(i.content), indent=1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b10fdab707a0d4a",
   "metadata": {},
   "source": [
    "vc_ls = vc_rag_result.retriever_result.items[0].content.split('\\\\n---\\\\n')\n",
    "for i in vc_ls:\n",
    "    if \"biomarker\" in i: print(i)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7f1510ef53a9d253",
   "metadata": {},
   "source": [
    "vc_ls = vc_rag_result.retriever_result.items[0].content.split('\\\\n---\\\\n')\n",
    "for i in vc_ls:\n",
    "    if \"treat\" in i: print(i)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d03ec43f6f02f608",
   "metadata": {},
   "source": [
    "q = \"Can you summarize systemic lupus erythematosus (SLE)? including common effects, biomarkers, treatments, and current challenges faced by Physicians and patients? provide in list format with details for each item.\"\n",
    "print(f\"Vector Response: \\n{v_rag.search(q, retriever_config={'top_k': 5}).answer}\")\n",
    "print(\"\\n===========================\\n\")\n",
    "print(f\"Vector + Cypher Response: \\n{vc_rag.search(q, retriever_config={'top_k': 5}).answer}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7d66300af9eac12",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo4j",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
